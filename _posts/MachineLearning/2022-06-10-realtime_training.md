---

layout: post
title:  实时训练
category: 架构
tags: MachineLearning
keywords: 实时训练

---

## 简介（未完成）

* TOC
{:toc}

推荐/广告系统是在线学习的理想应用之一。推荐系统有很自然的标签——如果一位用户点击一个推荐，那么这个预测就是正确的。
1. 并非所有推荐系统都需要在线预测。用户对房子、汽车、航班和酒店的偏好不太可能过一分钟就变了，因此对于这样的系统，持续学习并不太合理。
2. 在线学习对系统适应罕见事件至关重要。以黑色星期五在线购物为例，由于黑色星期五一年仅发生一次，因此亚马逊和其它电商网站不可能有足够多的历史数据来学习用户在那天的行为，因此它们的系统需要持续学习那天的状况以应对变化（名人事件类似）。
3. 在线学习还可以帮助解决冷启动（cold start）问题。冷启动是指新用户加入你的应用时，你还没有他们的信息。如果没有任何形式的在线学习，你就只能向新用户推荐一般性内容，直到你下一次以离线方式训练好模型。

在线学习并不意味着「无批量学习」。在在线学习方面最成功的公司也会同时以离线方式训练其模型，然后再将在线版本与离线版本组合起来。

理论挑战

1. 离线训练即 使用足够多 epoch 训练你的模型直到收敛，而在线学习没有 epoch——你的模型只会看见每个数据一次。
2. 在线学习也不存在收敛这个说法，基础数据分布会不断变化，没有什么可以收敛到的静态分布。
3. 在线学习的另一大理论挑战是模型评估。在传统的批训练中，你会在静态的留出测试集上评估模型。如果新模型在同一个测试集上优于现有模型，那我们就说新模型更好。但是，在线学习的目标是让模型适应不断变化的数据。如果更新后的模型是在现在的数据上训练的，而且我们知道现在的数据不同于过去的数据，那么再在旧有数据集上测试更新后的模型是不合理的。那么，我们该怎么知道在前 10 分钟的数据上训练的模型优于使用前 20 分钟的数据训练的模型呢？答案是必须在当前数据上比较两个模型。在线学习需要**在线评估**，但是向用户提供还未测试的模型听起来简直是灾难。不过，很多公司都这么做。新模型首先要进行离线测试，以确保它们不会造成灾难性后果，然后再通过复杂的 A/B 测试系统，与现有模型并行地进行在线评估。只有当新模型在该公司关心的某个指标上的表现优于现有模型时，它才能得到更广泛的部署。

## 实践挑战

1. 在线训练目前还没有标准的基础设施。


在线/实时训练其实输出的是一个模型的更新数据流，这里其实是最近上一批次产生的对模型造成变化被实时的发布到在线。离线其实会做批量天级别的训练，会发布一个全量的迁移参数模型，同时更回到线上。


[模型样本构建方案演进之路](https://zhuanlan.zhihu.com/p/546493272)以推荐系统为例：
1. t0时刻，端侧向推荐服务发起请求，要求为用户u1提供100个最匹配的商品
2. t1时刻，服务后端请求召回模型，获得了1000个商品
3. t2时刻，服务后端请求该1000个商品以及用户u1的特征，并向排序模型发起请求
4. t3时刻，排序模型完成推理，返回排序后的Top100商品
5. t4时刻，服务后端返回该100商品，端侧向用户展示商品
6. t5时刻，实际仅Top10商品向用户曝光并触发了用户点击，曝光和点击日志回传到服务后端
7. t6时刻，根据曝光和点击日志，构建样本，以对排序模型进行再训练或增量训练

样本生成的要求：当生成样本时，特征的时刻要与事件的时刻匹配，不能过早也不能过晚，否则将导致特征穿越。以如上时间线为例，t2时刻发生了实际的模型推理，这一事件在t6时刻转化成训练样本时，关联的应是t2时刻的特征值，即所谓的Point-in-Time Correct。

t6时刻构建样本时，有几种方案

1. 用户点击流 （也就是y）带有uid/itemId 信息，然后根据uid/itemId 信息向store查询x （这个过程可能会有特征穿越），然后拼凑的样本
    1. 对于只使用批式特征的模型，t6与t2的时间间隔远小于特征更新频率，可以认为方案是可靠的；
    2. 而对于使用了流式特征和即时特征的模型来说，特征更新频率越快，越容易发生特征穿越，不应使用该方案
2. 为了完全避免特征穿越，需要**将t2时刻查询到的特征记录成快照**（记录x），生成样本时Join该特征快照（也就是t6 拿到y 之后join x和y）
    1. 离线样本：特征快照写入离线存储，定时通过批处理实现Join，完成样本生成。**推荐排序系统单次请求可能对数百个商品进行排序，但最终曝光和点击的商品仅数个，导致特征快照数量级远大于曝光/点击流**，导致特征快照数据量大，进而导致Join时计算量大
    2. 特征快照写入Kafka，通过Flink实现双流Join，完成样本生成，用作离线或在线训练。
3. t6 将曝光/点击流（也就是y）insert到store，延迟数分钟后，再以Update方式写入特征快照x(t2 时刻将特征快照x写入 kafka)。
    1. 特征快照x中，同时保存了批式、流式、即时特征。然而，只有流式、即时特征容易引入特征穿越问题。因此：特征快照中可以只保存流式、即时特征；在样本生成时，再通过二次查询Feature Store补录批式特征
    2. 由于特征快照 x 数量远大于 y，因此采用先insert y ，再用x 更新的的方式，x 和 y 是同一个key，update 过程即 x 和y join 。


特征平台的数据一致性问题，说的就是特征的在线和离线存储的一致性问题。问题的本质就是在线离线有两条pipeline
![](/public/upload/machine/feature_consistency.png)
    
1. 砍掉离线pipeline，线上线下消费同一套数据。实时生成的样本积累到一定数据量再进行离线训练。但如果想为模型加入新的特征，就不得等加入新特征的样本积累一定的数据量了。
    ![](/public/upload/machine/feature_consistency_1.png)
2. 线上线下pipeline实现逻辑归一
    ![](/public/upload/machine/feature_consistency_2.png)

## 字节

[推荐系统流批一体实践](https://mp.weixin.qq.com/s/0ROxCZL9ZR7FAg98szBbVA)在推荐系统的整个数据处理链路中，流式处理和批式处理都占据着重要的位置。尤其是在特征计算模块，推荐系统需要为用户实时地推荐信息流，保证实时性和准确性，同时也需要进行模型训练以提升推荐准确性。**双数据链路**的设计带来了诸多问题。

![](/public/upload/machine/bytedance_onoff.png)

在流式链路中，我们接收用户请求，获得用户的实时在线特征，这些实时在线特征经过实时的流式处理之后，再结合在线特征库，就可以得到一个比较庞大的特征组。随后，将整个特征组输入到在线预测模型中，就可以得到预测的结果，从而实时地为用户推荐信息流。同时，这些特征也会被存入离线存储（如 HDFS）中，后续会利用这些特征进行线下的批式模型训练。对于离线训练来说，存入 HDFS 中的数据，经过批式的 ETL 处理后，输入到离线的模型训练中，训练出的模型可以用于更新在线服务的模型，从而更准确地服务用户。然而，正如上文所述，推荐系统的数据链路分了在线和离线两个体系，所以推荐系统在计算和使用在线特征和离线特征时，需要分别使用两种不同计算引擎和存储进行在、离线特征处理，带来了以下问题：
1. 对流处理和批处理分别维护两套代码，业务成本过高
2. 特征回溯难度大
3. 如何使用历史数据初始化状态难定义
4. 数据不统一，存储成本高

[5年迭代5次，抖音推荐系统演进历程](https://mp.weixin.qq.com/s/_c_YtNFOuOpcyWInQowgCw)特征生产的链路分为数据源抽取 / 拼接、状态存储、计算三个阶段，Flink SQL 完成特征数据的抽取和流式拼接，Flink State 完成特征计算的中间状态存储。

![](/public/upload/machine/bytedance_ai_platform.png)