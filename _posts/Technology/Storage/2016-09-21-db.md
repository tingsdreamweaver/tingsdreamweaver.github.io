---

layout: post
title: 数据库的一些知识
category: 技术
tags: Storage
keywords: db

---

## 简介

[数据库存储选型经验总结](https://mp.weixin.qq.com/s/YpRQa9YguOqJygJbdRZ-nA) 未读

[数据库治理的云原生之道 —— Database Mesh 2.0](https://mp.weixin.qq.com/s/q_-9u8gluTf7VCG0lkD86Q)

## 数据的组织

[从单机到分布式数据库存储系统的演进](https://mp.weixin.qq.com/s/dMk34u_9R2w1piU-yHHQ9Q)单机数据库存储，要从内存层和持久化层两个方面来解析。
1. 在内存层，仅说关系型数据库，其内存数据结构特点可以总结为：**一切都是“树”**。我们以最常见的 B+ 树为例，B+ 树具有以下突出的特点：
    1. In memory 操作效率非常高： B+ 树搜索时间复杂度是 log 级别；并且 B+ 树的叶子节点构成链表，非常有利于在内存中对数据进行 scan 操作。
    2. 磁盘操作效率高：B+ 树的 Fanout 足够大，树的层级较少，呈矮胖状，可以减少磁盘 IO 数；同时 B+ 树的非叶子节点只存索引数据，叶子节点存实际数据，能大大压缩树高，进一步减少磁盘 IO 数。
    3. 数据结构高度统一：数据 & 索引都可以直接组织成 B+ 树，因此代码的可维护性、可读性和开发效率都比较好。
2. 基于单机的 FS / 块存储去做持久化，我们会遇到哪些问题呢？
    1. 单机容量瓶颈：在 Database 层的单机服务器上运行着 database 进程，服务器上挂载了大量本地磁盘用作数据持久化。但一台物理服务器能挂载的磁盘容量总是有限的，这就导致了单机的容量瓶颈问题。
    2. 扩缩容困难：当容量、CPU 或者内存等资源不够时，我们需要进行扩容。在单机时代，扩容意味着将数据从这个磁盘搬迁到另一个磁盘。但不管我们是通过网络还是有线连接手段，都需要花费一定的时间，这可能导致业务较长时间的停写（不可用），因此扩缩容是非常困难的。
    2. 多份独立数据，成本高：如果我们要在“复制集”之间或者主备机之间去做数据冗余或数据同步，那么每新增一分计算能力（新增一个计算节点），就要新增一分存储冗余，就会导致存储成本提高。

## 存储

### 文件

关系型数据库中往往都包含 Log 数据和 Page 数据。

假定数据库存放数据的文件称为data file，数据库的内容在内存里是有缓存的，称为db buffer。某次操作，我们取了数据库某表格中的数据，这个数据会在内存中缓存一些时间。对这个数据的修改在开始时候也只是修改在内存中的内容。当db buffer已满或者遇到其他的情况，这些数据会写入data file。(为了维护这个db buffer和db file的一致性，引入了checkpoint)

db buffer的存在不仅提高了性能，系统也有机会对db buffer进行一定整理后集中写入，毕竟db数据随机写入的开销比较大。log file一般是追加内容，可以认为是顺序写。

### kv

MyRocks: MySQL + RocksDB，是单机 SQL over kv 的典型代表。
1. 核心理念：用 RocksDB 替换 InnoDB 。使用 RocksDB 能够有效缓解单机容量瓶颈的问题；
2. 特点：一是：数据可压缩比例较高。RocksDB 实现了一种比较优秀的压缩算法，根据实际调研结果显示，在关系型数据库场景，基本上它能实现 2-4 倍的压缩比，能有效缓解单机的容量瓶颈问题。例如，单机原本挂载了 10 块磁盘，只能承载 10 TB 数据，使用 RocksDB 就能在不改变硬件条件下帮助单机承载 20 TB 或 30 TB 等更多的数据；二是，顺序写性能较好，这也是 LSM-Tree 这种数据结构在 HDD 年代出现的核心原因。
3. 难点：Compaction 会导致性能抖动，且兼容性一般。众所周知，RocksDB 基于 LSM-Tree 构建，必然会遇到一些典型的 LSM-Tree-based 系统的问题。虽然 RocksDB 对顺序写特别友好，但它一定程度上牺牲了读性能—— RocksDB 在读的过程中会触发 Compaction，可能引发性能抖动，导致前台的写出现卡顿现象；同时，这一类 SQL over kv 解决方案的兼容性能表现较为一般。

### 计算存储分离

1. Amazon Aurora核心理念：计算存储分离，Log is Database。存储层带有特定的数据库计算逻辑，除了具备存储能力之外，还具备 Redo Log 解析、回放生成数据库 Page、维护多版本数据的能力。
2. Spanner 系: 计算存储分离，且 Share-Nothing。Spanner 系的数据库系统一般基于分布式 k-v 存储构建，由存储层保证事务特性，计算层做成纯计算的无状态节点。

## 列式存储

当一行数据有 100 个字段，而我们的分析程序只需要其中 5 个字段的时候，就很尴尬了。因为如果我们顺序解析读取数据，我们就要白白多读 20 倍的数据。那么，能不能跳着只读我们需要的字段呢？当然也是不行的，因为对于硬盘来说，顺序读远远要优于随机读。

![](/public/upload/storage/column_storage.png)

不过，这样存储之后，数据写入就变得有些麻烦了。原先我们只需要顺序追加写入数据，而现在我们需要向很多个文件去追加写入数据，那有没有什么好办法呢？对于追加写入的数据，我们可以先写 WAL 日志，然后再把数据更新到内存中，接着再从内存里面，定期导出按列存储的文件到硬盘上。事实上，在一个分布式的环境里，我们的数据其实并不能称之为 100% 的列存储。因为我们在分析数据的时候，可能需要多个列的组合筛选条件。所以，更合理的解决方案是**行列混合存储**。在单个服务器上，数据是列存储的，但是在全局，数据又根据行进行分区，分配到了不同的服务器节点上。

## 未来发展

在谈及数据库存储的未来演进时，首先我们可以思考一下**哪些因素会触发数据库存储架构的变革和演进**？答案可能包含：存储架构自身的革命、数据库理论的突破、或者新硬件冲击引发存储系统架构迭代。基于这三个方向的思考，我们总结了以下几个数据库存储系统的演进趋势：
1. 在 HTAP/HSAP 系统中，“实时”是第一关键词。为了支持实时，存储系统可能会发生架构演进和变革，因此我们需要探索：
    1. 行列存 All-in-one：既要存储行式的数据，又要存储列式的数据。
    2. 近实时，写时计算：我们需要在存储层实现写时计算的逻辑来支持实时性。
2. 在硬件变革趋势上，我们总结了三个变革方向：
    1. 前几年，我们可能更多关注 SSD、HDD。目前我们处于 SSD 往 persistent memory 转变的风口，那么如何利用 persistent memory 去定制软件架构？
    2. 计算单元变革：CPU 产品已经从 multi-core 变成了 many-core （从 96c 变成了 192c、384c）。要怎么利用多核的能力？对于非计算密集型的存储系统而言，多余的算力能否用来加速数据库算子？一些无锁的数据结构是不是需要要重新设计？以上都需要我们认真考虑。
    3. 网络设施变革：例如 RDMA ，以及可编程的 P4 交换机这类全新的一些网络设施，可能会对我们的软件架构特别是分布式存储架构造成较大的冲击。相应地，我们需要在存储侧做出调整。

[OceanBase CTO杨传辉：怎么理解HTAP？](https://mp.weixin.qq.com/s/b6Yo_Go9jwm4T30iKVpdTw) 未读

[基于AI算法的数据库异常监测系统的设计与实现](https://mp.weixin.qq.com/s/EUPREu-SRGJwqTWWeDlvxw)

## How do you build a database

摘自[How do you build a database? ](https://www.reddit.com/r/Database/comments/27u6dy/how_do_you_build_a_database/ciggal8/)，为防止链接失效，贴上原文。

Its a great question, and deserves a long answer.
Most database servers are built in C, and store data using B-tree type constructs. In the old days there was a product called C-Isam (c library for an indexed sequential access method) which is a low level library to help C programmers write data in B-tree format. So you need to know about btrees and understand what these are. BTree 很重要

Most databases store data separate to indexes. Lets assume a record (or row) is 800 bytes long and you write 5 rows of data to a file. If the row contains columns such as first name, last name, address etc. and you want to search for a specific record by last name, you can open the file and sequentially search through each record but this is very slow. Instead you open an index file which just contains the lastname and the position of the record in the data file. Then when you have the position you open the data file, lseek to that position and read the data. Because index data is very small it is much quicker to search through index files. Also as the index files are stored in btrees in it very quick to effectively do a quicksearch (divide and conquer) to find the record you are looking for. 一个表单单数据文件是不够的，需要一/多个索引文件。

So you understand for one "table" you will have a data file with the data and one (or many) index files. The first index file could be for lastname, the next could be to search by SS number etc. When the user defines their query to get some data, they decide which index file to search through. If you can find any info on C-ISAM (there used to be an open source version (or cheap commercial) called D-ISAM) you will understand this concept quite well.


Once you have stored data and have index files, using an ISAM type approach allows you to GET a record based on a value, or PUT a new record. However modern database servers all support SQL, so you need an SQL parser that translates the SQL statement into a sequence of related GETs. SQL may join 2 tables so an optimizer（优化器最初是为了加快join表的速度么？） is also needed to decide which table to read first (normally based on number of rows in each table and indexes available) and how to relate it to the next table. SQL can INSERT data so you need to parse that into PUT statements but it can also combine multiple INSERTS into transactions so you need a transaction manager to control this, and you will need transaction logs to store wip/completed transactions.


It is possible you will need some backup/restore commands to backup your data files and index files and maybe also your transaction log files, and if you really want to go for it you could write some replication tools to read your transaction log and replicate the transactions to a backup database on a different server. Note if you want your client programs (for example an SQL UI like phpmyadmin) to reside on separate machine than your database server you will need to write a connection manager that sends the SQL requests over TCP/IP to your server, then authenticate it using some credentials, parse the request, run your GETS and send back the data to the client.
So these database servers can be a lot of work, especially for one person. But you can create simple versions of these tools one at a time. Start with how to store data and indexes, and how to retrieve data using an ISAM type interface.
There are books out there - look for older books on mysql and msql, look for anything on google re btrees and isam, look for open source C libraries that already do isam. Get a good understanding on file IO on a linux machine using C. Many commercial databases now dont even use the filesystem for their data files because of cacheing issues - they write directly to raw disk. You want to just write to files initially.
I hope this helps a little bit.

概要内容：

1. 知道BTree 很重要
2. 一个表单单数据文件是不够的，需要一/多个索引文件，数据文件和索引文件分开存储
3. 有了数据文件和索引文件，你就可以读写数据了，但你需要SQL parser 将sql 翻译成读写操作，需要optimizer加快join表的速度，需要Transaction manager 管理事务
4. 备份儿/恢复数据文件、索引文件、Transaction log文件。如果支持客户端程序的话，还需要一个Connection manager

## 其它

[数据库治理利器：动态读写分离](https://mp.weixin.qq.com/s/EfYnwL75rNRvcP42Qh1fKg) 未读t